{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group 5:** Marwin Prenner & Marcel Dielacher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook explores two different approaches (centralized learning & federated learning) for training machine learning models on survey data related to lung cancer. The dataset comprises responses from individuals participating in a survey related to lung cancer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In this section, we'll import the necessary libraries and modules for our analysis. You can run the cell below to ensure all dependencies are installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install all important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flwr in c:\\users\\marwi\\anaconda3\\envs\\fml\\lib\\site-packages (from -r requirements.txt (line 1)) (1.6.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: seaborn in c:\\users\\marwi\\anaconda3\\envs\\fml\\lib\\site-packages (from -r requirements.txt (line 2)) (0.13.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\marwi\\anaconda3\\envs\\fml\\lib\\site-packages (from -r requirements.txt (line 3)) (2.1.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\marwi\\anaconda3\\envs\\fml\\lib\\site-packages (from -r requirements.txt (line 4)) (3.8.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\marwi\\anaconda3\\envs\\fml\\lib\\site-packages (from -r requirements.txt (line 5)) (1.26.3)\n",
      "Collecting sklearn (from -r requirements.txt (line 7))\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import flwr as fl\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"survey_lung_cancer.csv\") # import data from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the realm of data science, the process of exploring and comprehending the dataset is pivotal for successful analysis and modeling. The \"Data Understanding\" phase serves as a foundational step in the overall data science lifecycle. This section focuses on gaining insights into the structure, content, and quality of the dataset, laying the groundwork for subsequent stages such as data preparation and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SMOKING</th>\n",
       "      <th>YELLOW_FINGERS</th>\n",
       "      <th>ANXIETY</th>\n",
       "      <th>PEER_PRESSURE</th>\n",
       "      <th>CHRONIC DISEASE</th>\n",
       "      <th>FATIGUE</th>\n",
       "      <th>ALLERGY</th>\n",
       "      <th>WHEEZING</th>\n",
       "      <th>ALCOHOL CONSUMING</th>\n",
       "      <th>COUGHING</th>\n",
       "      <th>SHORTNESS OF BREATH</th>\n",
       "      <th>SWALLOWING DIFFICULTY</th>\n",
       "      <th>CHEST PAIN</th>\n",
       "      <th>LUNG_CANCER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  GENDER  AGE  SMOKING  YELLOW_FINGERS  ANXIETY  PEER_PRESSURE  \\\n",
       "0      M   69        1               2        2              1   \n",
       "1      M   74        2               1        1              1   \n",
       "2      F   59        1               1        1              2   \n",
       "3      M   63        2               2        2              1   \n",
       "4      F   63        1               2        1              1   \n",
       "\n",
       "   CHRONIC DISEASE  FATIGUE   ALLERGY   WHEEZING  ALCOHOL CONSUMING  COUGHING  \\\n",
       "0                1         2         1         2                  2         2   \n",
       "1                2         2         2         1                  1         1   \n",
       "2                1         2         1         2                  1         2   \n",
       "3                1         1         1         1                  2         1   \n",
       "4                1         1         1         2                  1         2   \n",
       "\n",
       "   SHORTNESS OF BREATH  SWALLOWING DIFFICULTY  CHEST PAIN LUNG_CANCER  \n",
       "0                    2                      2           2         YES  \n",
       "1                    2                      2           2         YES  \n",
       "2                    2                      1           2          NO  \n",
       "3                    1                      2           2          NO  \n",
       "4                    2                      1           1          NO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informations About The Dataset :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 309 entries, 0 to 308\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   GENDER                 309 non-null    object\n",
      " 1   AGE                    309 non-null    int64 \n",
      " 2   SMOKING                309 non-null    int64 \n",
      " 3   YELLOW_FINGERS         309 non-null    int64 \n",
      " 4   ANXIETY                309 non-null    int64 \n",
      " 5   PEER_PRESSURE          309 non-null    int64 \n",
      " 6   CHRONIC DISEASE        309 non-null    int64 \n",
      " 7   FATIGUE                309 non-null    int64 \n",
      " 8   ALLERGY                309 non-null    int64 \n",
      " 9   WHEEZING               309 non-null    int64 \n",
      " 10  ALCOHOL CONSUMING      309 non-null    int64 \n",
      " 11  COUGHING               309 non-null    int64 \n",
      " 12  SHORTNESS OF BREATH    309 non-null    int64 \n",
      " 13  SWALLOWING DIFFICULTY  309 non-null    int64 \n",
      " 14  CHEST PAIN             309 non-null    int64 \n",
      " 15  LUNG_CANCER            309 non-null    object\n",
      "dtypes: int64(14), object(2)\n",
      "memory usage: 38.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Informations About The Dataset :\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of This Dataset :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SMOKING</th>\n",
       "      <th>YELLOW_FINGERS</th>\n",
       "      <th>ANXIETY</th>\n",
       "      <th>PEER_PRESSURE</th>\n",
       "      <th>CHRONIC DISEASE</th>\n",
       "      <th>FATIGUE</th>\n",
       "      <th>ALLERGY</th>\n",
       "      <th>WHEEZING</th>\n",
       "      <th>ALCOHOL CONSUMING</th>\n",
       "      <th>COUGHING</th>\n",
       "      <th>SHORTNESS OF BREATH</th>\n",
       "      <th>SWALLOWING DIFFICULTY</th>\n",
       "      <th>CHEST PAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>62.673139</td>\n",
       "      <td>1.563107</td>\n",
       "      <td>1.569579</td>\n",
       "      <td>1.498382</td>\n",
       "      <td>1.501618</td>\n",
       "      <td>1.504854</td>\n",
       "      <td>1.673139</td>\n",
       "      <td>1.556634</td>\n",
       "      <td>1.556634</td>\n",
       "      <td>1.556634</td>\n",
       "      <td>1.579288</td>\n",
       "      <td>1.640777</td>\n",
       "      <td>1.469256</td>\n",
       "      <td>1.556634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.210301</td>\n",
       "      <td>0.496806</td>\n",
       "      <td>0.495938</td>\n",
       "      <td>0.500808</td>\n",
       "      <td>0.500808</td>\n",
       "      <td>0.500787</td>\n",
       "      <td>0.469827</td>\n",
       "      <td>0.497588</td>\n",
       "      <td>0.497588</td>\n",
       "      <td>0.497588</td>\n",
       "      <td>0.494474</td>\n",
       "      <td>0.480551</td>\n",
       "      <td>0.499863</td>\n",
       "      <td>0.497588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AGE     SMOKING  YELLOW_FINGERS     ANXIETY  PEER_PRESSURE  \\\n",
       "count  309.000000  309.000000      309.000000  309.000000     309.000000   \n",
       "mean    62.673139    1.563107        1.569579    1.498382       1.501618   \n",
       "std      8.210301    0.496806        0.495938    0.500808       0.500808   \n",
       "min     21.000000    1.000000        1.000000    1.000000       1.000000   \n",
       "25%     57.000000    1.000000        1.000000    1.000000       1.000000   \n",
       "50%     62.000000    2.000000        2.000000    1.000000       2.000000   \n",
       "75%     69.000000    2.000000        2.000000    2.000000       2.000000   \n",
       "max     87.000000    2.000000        2.000000    2.000000       2.000000   \n",
       "\n",
       "       CHRONIC DISEASE    FATIGUE     ALLERGY     WHEEZING  ALCOHOL CONSUMING  \\\n",
       "count       309.000000  309.000000  309.000000  309.000000         309.000000   \n",
       "mean          1.504854    1.673139    1.556634    1.556634           1.556634   \n",
       "std           0.500787    0.469827    0.497588    0.497588           0.497588   \n",
       "min           1.000000    1.000000    1.000000    1.000000           1.000000   \n",
       "25%           1.000000    1.000000    1.000000    1.000000           1.000000   \n",
       "50%           2.000000    2.000000    2.000000    2.000000           2.000000   \n",
       "75%           2.000000    2.000000    2.000000    2.000000           2.000000   \n",
       "max           2.000000    2.000000    2.000000    2.000000           2.000000   \n",
       "\n",
       "         COUGHING  SHORTNESS OF BREATH  SWALLOWING DIFFICULTY  CHEST PAIN  \n",
       "count  309.000000           309.000000             309.000000  309.000000  \n",
       "mean     1.579288             1.640777               1.469256    1.556634  \n",
       "std      0.494474             0.480551               0.499863    0.497588  \n",
       "min      1.000000             1.000000               1.000000    1.000000  \n",
       "25%      1.000000             1.000000               1.000000    1.000000  \n",
       "50%      2.000000             2.000000               1.000000    2.000000  \n",
       "75%      2.000000             2.000000               2.000000    2.000000  \n",
       "max      2.000000             2.000000               2.000000    2.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Summary of This Dataset :\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset have 33 duplicates. Valid data: 276\n"
     ]
    }
   ],
   "source": [
    "print(f\"This dataset have {data[data.duplicated()].shape[0]} duplicates. Valid data: {len(data) - data[data.duplicated()].shape[0]}\")\n",
    "data.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation is a crucial step in the data analysis process. It involves cleaning, transforming, and organizing raw data into a format suitable for analysis. Effective data preparation ensures that the data used for analysis is accurate, complete, and relevant, leading to more meaningful insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelEncoder = LabelEncoder()\n",
    "\n",
    "data[\"GENDER\"] = data[\"GENDER\"].replace({\"M\" : \"Male\" , \"F\" : \"Female\"})\n",
    "data[\"LUNG_CANCER\"] = LabelEncoder.fit_transform(data[\"LUNG_CANCER\"])\n",
    "data = pd.get_dummies(data, columns= [\"GENDER\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SMOKING</th>\n",
       "      <th>YELLOW_FINGERS</th>\n",
       "      <th>ANXIETY</th>\n",
       "      <th>PEER_PRESSURE</th>\n",
       "      <th>CHRONIC DISEASE</th>\n",
       "      <th>FATIGUE</th>\n",
       "      <th>ALLERGY</th>\n",
       "      <th>WHEEZING</th>\n",
       "      <th>ALCOHOL CONSUMING</th>\n",
       "      <th>COUGHING</th>\n",
       "      <th>SHORTNESS OF BREATH</th>\n",
       "      <th>SWALLOWING DIFFICULTY</th>\n",
       "      <th>CHEST PAIN</th>\n",
       "      <th>LUNG_CANCER</th>\n",
       "      <th>GENDER_Female</th>\n",
       "      <th>GENDER_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SMOKING  YELLOW_FINGERS  ANXIETY  PEER_PRESSURE  CHRONIC DISEASE  \\\n",
       "0   69        1               2        2              1                1   \n",
       "1   74        2               1        1              1                2   \n",
       "2   59        1               1        1              2                1   \n",
       "3   63        2               2        2              1                1   \n",
       "4   63        1               2        1              1                1   \n",
       "\n",
       "   FATIGUE   ALLERGY   WHEEZING  ALCOHOL CONSUMING  COUGHING  \\\n",
       "0         2         1         2                  2         2   \n",
       "1         2         2         1                  1         1   \n",
       "2         2         1         2                  1         2   \n",
       "3         1         1         1                  2         1   \n",
       "4         1         1         2                  1         2   \n",
       "\n",
       "   SHORTNESS OF BREATH  SWALLOWING DIFFICULTY  CHEST PAIN  LUNG_CANCER  \\\n",
       "0                    2                      2           2            1   \n",
       "1                    2                      2           2            1   \n",
       "2                    2                      1           2            0   \n",
       "3                    1                      2           2            0   \n",
       "4                    2                      1           1            0   \n",
       "\n",
       "   GENDER_Female  GENDER_Male  \n",
       "0          False         True  \n",
       "1          False         True  \n",
       "2           True        False  \n",
       "3          False         True  \n",
       "4           True        False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data : (220, 16), (220,)\n",
      "Shape of testing data : (56, 16), (56,)\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "\n",
    "x = data.drop(\"LUNG_CANCER\", axis = 1)\n",
    "y = data[\"LUNG_CANCER\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "print(f\"Shape of training data : {x_train.shape}, {y_train.shape}\")\n",
    "print(f\"Shape of testing data : {x_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centralized Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the realm of machine learning, centralized learning refers to a training paradigm where a single, centralized entity or server is responsible for collecting, storing, and processing all the data for model training. This approach stands in contrast to decentralized or federated learning, where data is distributed across multiple devices or locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a statistical method used for binary classification, predicting the probability of an observation belonging to one of two classes. It is widely employed in machine learning when the dependent variable is categorical and represents two outcomes, typically coded as 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      "[[ 8  4]\n",
      " [ 0 44]]\n",
      "\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80        12\n",
      "           1       0.92      1.00      0.96        44\n",
      "\n",
      "    accuracy                           0.93        56\n",
      "   macro avg       0.96      0.83      0.88        56\n",
      "weighted avg       0.93      0.93      0.92        56\n",
      "\n",
      "\n",
      "Logistic Regression is Accuracy 92.86 %\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "lr_pred = lr.predict(x_test)\n",
    "print(f\"Confusion Matrix : \\n{confusion_matrix(y_test, lr_pred)}\\n\")\n",
    "print(f\"Classification Report : \\n{classification_report(y_test, lr_pred)}\\n\")\n",
    "print(f\"Logistic Regression is Accuracy {round(accuracy_score(y_test, lr_pred)*100, ndigits = 2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is an ensemble learning algorithm widely used in machine learning for both classification and regression tasks. It operates by constructing a multitude of decision trees during training and outputs the mode (for classification) or the mean (for regression) of the individual trees for predictions.\n",
    "\n",
    "#### How Random Forest Works\n",
    "\n",
    "1. **Bootstrap Sampling (Bagging):** Random Forest starts by creating multiple random subsets of the original dataset through a process called bootstrap sampling. This involves randomly selecting samples with replacement, resulting in diverse subsets for each tree.\n",
    "\n",
    "2. **Feature Randomization:** For each tree, a random subset of features is considered at each split. This helps to introduce diversity among the trees and prevents the dominance of one particular feature.\n",
    "\n",
    "3. **Building Decision Trees:** Decision trees are constructed using the bootstrapped datasets and random subsets of features. Each tree in the forest is grown deep, often without pruning, to capture complex relationships in the data.\n",
    "\n",
    "4. **Voting (Classification) or Averaging (Regression):** During prediction, the Random Forest aggregates the outputs of all individual trees. For classification tasks, the mode (most frequent class) is taken as the final prediction. For regression tasks, the mean of all predictions is considered.\n",
    "\n",
    "#### Advantages of Random Forest\n",
    "\n",
    "- **Robust to Overfitting:** The ensemble nature of Random Forest helps mitigate overfitting, as the aggregation of multiple trees tends to generalize well to unseen data.\n",
    "  \n",
    "- **High Accuracy:** Random Forest often provides high accuracy in both classification and regression tasks due to the combination of diverse decision trees.\n",
    "\n",
    "- **Feature Importance:** The algorithm provides a measure of feature importance, helping in identifying the most relevant features in the dataset.\n",
    "\n",
    "- **Handles Missing Values:** Random Forest can effectively handle missing values in the dataset without a need for imputation.\n",
    "\n",
    "#### Use Cases\n",
    "\n",
    "Random Forest is suitable for a wide range of applications, including but not limited to:\n",
    "\n",
    "- Classification tasks in areas such as finance, healthcare, and image recognition.\n",
    "- Regression tasks for predicting numerical values, like stock prices or housing prices.\n",
    "- Identifying important features in datasets.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "Random Forest is a powerful and versatile machine learning algorithm that leverages the strength of multiple decision trees to provide robust and accurate predictions. Its ability to handle various types of data and avoid overfitting makes it a popular choice in the machine learning community.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 6  6]\n",
      " [ 0 44]]\n",
      "\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67        12\n",
      "           1       0.88      1.00      0.94        44\n",
      "\n",
      "    accuracy                           0.89        56\n",
      "   macro avg       0.94      0.75      0.80        56\n",
      "weighted avg       0.91      0.89      0.88        56\n",
      "\n",
      "Random Forest Classifier Accuracy is 89.29 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators = 100, random_state = random_state) \n",
    "rfc.fit(x_train, y_train)\n",
    "rfc_pred = rfc.predict(x_test)\n",
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, rfc_pred)}\\n\")\n",
    "print(f\"Report:\\n{classification_report(y_test, rfc_pred)}\")\n",
    "print(f\"Random Forest Classifier Accuracy is {round(accuracy_score(y_test, rfc_pred)*100, ndigits = 2)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.227406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ALLERGY</td>\n",
       "      <td>0.075966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YELLOW_FINGERS</td>\n",
       "      <td>0.073808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ALCOHOL CONSUMING</td>\n",
       "      <td>0.072706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PEER_PRESSURE</td>\n",
       "      <td>0.068384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHRONIC DISEASE</td>\n",
       "      <td>0.066669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FATIGUE</td>\n",
       "      <td>0.056776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COUGHING</td>\n",
       "      <td>0.048466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SWALLOWING DIFFICULTY</td>\n",
       "      <td>0.045043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WHEEZING</td>\n",
       "      <td>0.044383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CHEST PAIN</td>\n",
       "      <td>0.044090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANXIETY</td>\n",
       "      <td>0.042233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SHORTNESS OF BREATH</td>\n",
       "      <td>0.035692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GENDER_Female</td>\n",
       "      <td>0.034594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOKING</td>\n",
       "      <td>0.033805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GENDER_Male</td>\n",
       "      <td>0.029980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Feature  Importance\n",
       "0                     AGE    0.227406\n",
       "7                ALLERGY     0.075966\n",
       "2          YELLOW_FINGERS    0.073808\n",
       "9       ALCOHOL CONSUMING    0.072706\n",
       "4           PEER_PRESSURE    0.068384\n",
       "5         CHRONIC DISEASE    0.066669\n",
       "6                FATIGUE     0.056776\n",
       "10               COUGHING    0.048466\n",
       "12  SWALLOWING DIFFICULTY    0.045043\n",
       "8                WHEEZING    0.044383\n",
       "13             CHEST PAIN    0.044090\n",
       "3                 ANXIETY    0.042233\n",
       "11    SHORTNESS OF BREATH    0.035692\n",
       "14          GENDER_Female    0.034594\n",
       "1                 SMOKING    0.033805\n",
       "15            GENDER_Male    0.029980"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df = pd.DataFrame({'Feature': data.drop(\"LUNG_CANCER\", axis=1).columns, 'Importance': rfc.feature_importances_})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVM) are a powerful class of supervised learning algorithms used for classification and regression tasks. SVMs are particularly effective in high-dimensional spaces and are widely used in machine learning and data analysis.\n",
    "\n",
    "#### Overview\n",
    "\n",
    "At its core, an SVM works by finding the optimal hyperplane that separates data points into different classes. The hyperplane is chosen such that it maximally separates the instances of different classes while maintaining a margin of separation. The instances that lie on the edges of the margin are called support vectors, hence the name of the algorithm.\n",
    "\n",
    "####  Key Concepts\n",
    "\n",
    "1. **Hyperplane:** In a two-dimensional space, a hyperplane is a simple line, while in higher dimensions, it becomes a hyperplane. SVM aims to find the hyperplane that best separates data points of different classes.\n",
    "\n",
    "2. **Margin:** The margin is the distance between the hyperplane and the nearest data point from either class. SVM seeks to maximize this margin, providing robustness to the model.\n",
    "\n",
    "3. **Support Vectors:** Support vectors are the data points that lie on the edges of the margin. These instances play a crucial role in determining the optimal hyperplane and are essential for the SVM algorithm.\n",
    "\n",
    "####  Types of SVM\n",
    "\n",
    "1. **Linear SVM:** This is suitable for linearly separable data, where a straight line can effectively divide the classes.\n",
    "\n",
    "2. **Non-linear SVM (Kernel SVM):** When the data is not linearly separable, SVM can use a kernel function to map the input features into a higher-dimensional space, making it possible to find a hyperplane that separates the classes.\n",
    "\n",
    "####  Advantages\n",
    "\n",
    "- Effective in high-dimensional spaces.\n",
    "- Robust to overfitting, especially in high-dimensi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 9  3]\n",
      " [ 0 44]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        12\n",
      "           1       0.94      1.00      0.97        44\n",
      "\n",
      "    accuracy                           0.95        56\n",
      "   macro avg       0.97      0.88      0.91        56\n",
      "weighted avg       0.95      0.95      0.94        56\n",
      "\n",
      "\n",
      "Support Vector Machine Accuracy is 94.64 %\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C = 100, gamma = 0.002)\n",
    "svm.fit(x_train, y_train)\n",
    "svm_pred = svm.predict(x_test)\n",
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, svm_pred)}\\n\")\n",
    "print(f\"Classification Report: \\n{classification_report(y_test, svm_pred)}\\n\")\n",
    "print(f\"Support Vector Machine Accuracy is {round(accuracy_score(y_test, svm_pred)*100, ndigits = 2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning with Flower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is Federated Learning?\n",
    "Federated Learning is a decentralized machine learning approach that allows model training across multiple devices or edge nodes without the need to transfer raw data to a central server. In this paradigm, models are trained locally on individual devices using their respective data, and only the model updates are transmitted to a central server, where they are aggregated to improve the global model.\n",
    "\n",
    "##### How Federated Learning Works\n",
    "\n",
    "The Federated Learning process typically involves the following steps:\n",
    "\n",
    "1. **Initialization:**\n",
    "   - A global model is initialized on a central server.\n",
    "\n",
    "2. **Local Training:**\n",
    "   - The global model is sent to participating devices.\n",
    "   - Each device trains the model using its local data, making updates based on its specific context.\n",
    "\n",
    "3. **Model Updates:**\n",
    "   - Only the model updates, not the raw data, are sent back to the central server.\n",
    "\n",
    "4. **Aggregation:**\n",
    "   - The central server aggregates the received updates from all participating devices to improve the global model.\n",
    "\n",
    "5. **Iteration:**\n",
    "   - Steps 2-4 are repeated iteratively to refine the global model collaboratively.\n",
    "\n",
    "##### Advantages of Federated Learning\n",
    "\n",
    "- **Privacy Preservation:**\n",
    "  - Federated Learning helps address privacy concerns by keeping data localized. Raw data never leaves individual devices, reducing the risk of sensitive information exposure.\n",
    "\n",
    "- **Edge Computing:**\n",
    "  - It leverages edge devices for local model training, making it suitable for scenarios with resource-constrained or bandwidth-limited devices.\n",
    "\n",
    "- **Decentralized Training:**\n",
    "  - Enables training on diverse datasets, reflecting variations in local environments and user behaviors.\n",
    "\n",
    "- **Reduced Communication Overhead:**\n",
    "  - Transmitting only model updates instead of raw data minimizes communication overhead, making it efficient for devices with limited network capabilities.\n",
    "\n",
    "##### Challenges and Considerations\n",
    "\n",
    "- **Heterogeneity:**\n",
    "  - Devices may have diverse data distributions and capabilities, requiring careful consideration in model aggregation.\n",
    "\n",
    "- **Security Concerns:**\n",
    "  - Federated Learning introduces new security challenges, such as the potential for model inversion attacks. Robust security measures must be implemented.\n",
    "\n",
    "- **Communication Delays:**\n",
    "  - Depending on the network conditions, communication delays between devices and the central server may impact the efficiency of the training process.\n",
    "\n",
    "##### Conclusion\n",
    "\n",
    "Federated Learning offers a privacy-preserving and collaborative approach to machine learning, making it well-suited for scenarios where data privacy is a priority or where edge devices play a crucial role in the learning process.\n",
    "\n",
    "#### What is Flower?\n",
    "\n",
    "Flower is a Python library designed to facilitate federated learning, a machine learning paradigm where the model is trained across decentralized devices or servers holding local data samples. The goal is to enable collaborative model training without sharing raw data.\n",
    "\n",
    "##### Features\n",
    "\n",
    "Flower offers several key features for federated learning:\n",
    "\n",
    "1. **Decentralized Training**\n",
    "\n",
    "Flower provides tools for training machine learning models across multiple devices or servers in a decentralized manner. Each device holds its local dataset, and model updates are aggregated without exchanging raw data.\n",
    "\n",
    "2. **Privacy-Preserving**\n",
    "\n",
    "By design, federated learning aims to preserve the privacy of local data. Flower ensures that the raw data never leaves the local device, as only model updates are shared during the training process.\n",
    "\n",
    "3. **Scalability**\n",
    "\n",
    "The library is designed to scale efficiently, making it suitable for federated learning scenarios involving a large number of devices or servers. This scalability is essential for applications with diverse and extensive datasets.\n",
    "\n",
    "4. **Compatibility with PyTorch and TensorFlow**\n",
    "\n",
    "Flower is compatible with popular deep learning frameworks like PyTorch and TensorFlow, making it accessible to a broad audience. This allows practitioners to leverage familiar tools while adopting federated learning techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset\n",
      "Client 1: 73 Datenpunkte\n",
      "Client 2: 73 Datenpunkte\n",
      "Client 3: 74 Datenpunkte\n",
      "\n",
      "Testset:\n",
      "Client 1: 18 Datenpunkte\n",
      "Client 2: 18 Datenpunkte\n",
      "Client 3: 20 Datenpunkte\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 3\n",
    "\n",
    "# TRAINSET\n",
    "\n",
    "num_data_points = len(x_train)\n",
    "\n",
    "# Berechne die Größe jedes Teils\n",
    "chunk_size = num_data_points // NUM_CLIENTS\n",
    "\n",
    "# Initialisiere Listen für die aufgeteilten Daten\n",
    "x_train_chunks = []\n",
    "y_train_chunks = []\n",
    "\n",
    "# Teile die Daten in die gewünschte Anzahl von Teilen auf\n",
    "for i in range(NUM_CLIENTS):\n",
    "    start_index = i * chunk_size\n",
    "    end_index = (i + 1) * chunk_size if i < NUM_CLIENTS - 1 else num_data_points\n",
    "    \n",
    "    x_chunk = x_train[start_index:end_index]\n",
    "    y_chunk = y_train[start_index:end_index]\n",
    "    \n",
    "    x_train_chunks.append(x_chunk)\n",
    "    y_train_chunks.append(y_chunk)\n",
    "\n",
    "print(\"Trainset\")\n",
    "# Beispiel: Drucke die Größe jedes Teils\n",
    "for i, y_chunk in enumerate(y_train_chunks):\n",
    "    print(f\"Client {i + 1}: {len(y_chunk)} Datenpunkte\")\n",
    "\n",
    "####################\n",
    "\n",
    "\n",
    "# TEST\n",
    "num_data_points = len(x_test)\n",
    "\n",
    "chunk_size = num_data_points // NUM_CLIENTS\n",
    "\n",
    "x_test_chunks = []\n",
    "y_test_chunks = []\n",
    "\n",
    "# Teile die Daten in die gewünschte Anzahl von Teilen auf\n",
    "for i in range(NUM_CLIENTS):\n",
    "    start_index = i * chunk_size\n",
    "    end_index = (i + 1) * chunk_size if i < NUM_CLIENTS - 1 else num_data_points\n",
    "    \n",
    "    x_chunk = x_test[start_index:end_index]\n",
    "    y_chunk = y_test[start_index:end_index]\n",
    "    \n",
    "    x_test_chunks.append(x_chunk)\n",
    "    y_test_chunks.append(y_chunk)\n",
    "\n",
    "# Beispiel: Drucke die Größe jedes Teils\n",
    "print(\"\")\n",
    "print(\"Testset:\")\n",
    "for i, y_chunk in enumerate(y_test_chunks):\n",
    "    print(f\"Client {i + 1}: {len(y_chunk)} Datenpunkte\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Teile den Datensatz auf die Clients auf\n",
    "NUM_CLIENTS = 3\n",
    "client_data = []\n",
    "\n",
    "\n",
    "# Teile die Daten zufällig auf die Clients auf\n",
    "for _ in range(NUM_CLIENTS):\n",
    "    client_train, client_test = train_test_split(data, test_size=0.2)\n",
    "    client_data.append((client_train, client_test))\n",
    "\n",
    "# Vorverarbeitung für jeden Client\n",
    "for i in range(NUM_CLIENTS):\n",
    "    train, test = client_data[i]\n",
    "    \n",
    "    # Extrahiere Features und Zielvariable\n",
    "    X_train = train.drop(\"LUNG_CANCER\", axis=1)\n",
    "    y_train = train[\"LUNG_CANCER\"]\n",
    "    X_test = test.drop(\"LUNG_CANCER\", axis=1)\n",
    "    y_test = test[\"LUNG_CANCER\"]\n",
    "    \n",
    "    # Skalieren der Daten (wichtig für viele ML-Algorithmen)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Speichere die vorverarbeiteten Daten zurück in client_data\n",
    "    client_data[i] = (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teile den Datensatz auf die Clients auf\n",
    "NUM_CLIENTS = 10\n",
    "client_data = []\n",
    " \n",
    "from sklearn.model_selection import KFold\n",
    " \n",
    "# Teile den Datensatz in k einzigartige Teile\n",
    "kf = KFold(n_splits=NUM_CLIENTS, shuffle=True, random_state=random_state)\n",
    " \n",
    "# Erstelle Client-Daten aus jedem KFold-Teil\n",
    "client_data = []\n",
    "for train_index, test_index in kf.split(data):\n",
    "    client_train, client_test = data.iloc[train_index], data.iloc[test_index]\n",
    "    client_data.append((client_train, client_test))\n",
    " \n",
    "# Führe die Vorverarbeitung für jeden Client durch\n",
    "for i in range(NUM_CLIENTS):\n",
    "    train, test = client_data[i]\n",
    " \n",
    " \n",
    "# Teile die Daten zufällig auf die Clients auf\n",
    "#for _ in range(NUM_CLIENTS):\n",
    "#    client_train, client_test = train_test_split(data, test_size=0.2)\n",
    "#    client_data.append((client_train, client_test))\n",
    " \n",
    "# Vorverarbeitung für jeden Client\n",
    "#for i in range(NUM_CLIENTS):\n",
    "#    train, test = client_data[i]\n",
    "   \n",
    "    # Extrahiere Features und Zielvariable\n",
    "    X_train = train.drop(\"LUNG_CANCER\", axis=1)\n",
    "    y_train = train[\"LUNG_CANCER\"]\n",
    "    X_test = test.drop(\"LUNG_CANCER\", axis=1)\n",
    "    y_test = test[\"LUNG_CANCER\"]\n",
    "   \n",
    "    # Skalieren der Daten (wichtig für viele ML-Algorithmen)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    " \n",
    "    # Speichere die vorverarbeiteten Daten zurück in client_data\n",
    "    client_data[i] = (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[39mreturn\u001b[39;00m accuracy, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_test), {}\n\u001b[1;32m     20\u001b[0m \u001b[39m# Initialisiere die Clients und starte das föderierte Training\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m client_models \u001b[39m=\u001b[39m [RandomForestClient(x_train_chunks, y_train_chunks, x_test_chunks, y_test_chunks) \u001b[39mfor\u001b[39;00m x_train_chunks, y_train_chunks, x_test_chunks, y_test_chunks \u001b[39min\u001b[39;00m client_data]\n\u001b[1;32m     22\u001b[0m \u001b[39m# client_models = [RandomForestClient(X_train, y_train, X_test, y_test) for X_train, y_train, X_test, y_test in client_data]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[113], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[39mreturn\u001b[39;00m accuracy, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_test), {}\n\u001b[1;32m     20\u001b[0m \u001b[39m# Initialisiere die Clients und starte das föderierte Training\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m client_models \u001b[39m=\u001b[39m [RandomForestClient(x_train_chunks, y_train_chunks, x_test_chunks, y_test_chunks) \u001b[39mfor\u001b[39;00m x_train_chunks, y_train_chunks, x_test_chunks, y_test_chunks \u001b[39min\u001b[39;00m client_data]\n\u001b[1;32m     22\u001b[0m \u001b[39m# client_models = [RandomForestClient(X_train, y_train, X_test, y_test) for X_train, y_train, X_test, y_test in client_data]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "# Flower-Client-Definition\n",
    "class RandomForestClient(fl.client.NumPyClient):\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.model = RandomForestClassifier(n_estimators=100)\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "        self.X_test, self.y_test = X_test, y_test\n",
    "\n",
    "    def get_parameters(self):\n",
    "        # was soll in diese methode (einfach von tutorial übernommen)\n",
    "        return []\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        return self.get_parameters(), len(self.X_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        accuracy = self.model.score(self.X_test, self.y_test)\n",
    "        return accuracy, len(self.X_test), {}\n",
    "\n",
    "# Initialisiere die Clients und starte das föderierte Training\n",
    "client_models = [RandomForestClient(x_train_chunks, y_train_chunks, x_test_chunks, y_test_chunks) for x_train_chunks, y_train_chunks, x_test_chunks, y_test_chunks in client_data]\n",
    "# client_models = [RandomForestClient(X_train, y_train, X_test, y_test) for X_train, y_train, X_test, y_test in client_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for client in range(len(x_train_chunks)):\n",
    "    print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Accuracy: 0.7777777777777778\n",
      "Client Accuracy: 0.8888888888888888\n",
      "Client Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "for client in range(len(x_train_chunks)):\n",
    "    #X_train, y_train, X_test, y_test = x_train_chunks[client], y_train_chunks, x_test_chunks, y_test_chunks\n",
    "    rfc = RandomForestClassifier(n_estimators = 100, random_state = random_state) \n",
    "\n",
    "    # Trainiere das Modell\n",
    "    rfc.fit(x_train_chunks[client], y_train_chunks[client])\n",
    "\n",
    "    # Evaluiere das Modell\n",
    "    accuracy = rfc.score(x_test_chunks[client], y_test_chunks[client])\n",
    "    print(f\"Client Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Client Accuracy: 0.7777777777777778\n",
    "Client Accuracy: 0.8888888888888888\n",
    "Client Accuracy: 0.9\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b67225186701176d63f31892b142f892e9d99d98ee3c8377add80c87c7a35978"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
